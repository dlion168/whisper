{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v5hvo8QWN-a9"
   },
   "source": [
    "# Installing Whisper\n",
    "\n",
    "The commands below will install the Python packages needed to use Whisper models and evaluate the transcription results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ZsJUxc0aRsAf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/whisper.git\n",
      "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-hp83nz9u\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-hp83nz9u\n",
      "  Resolved https://github.com/openai/whisper.git to commit 0a60fcaa9b86748389a656aa013c416030287d47\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting triton==2.0.0 (from openai-whisper==20230918)\n",
      "  Downloading triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numba in /home/evan/anaconda3/lib/python3.11/site-packages (from openai-whisper==20230918) (0.57.0)\n",
      "Requirement already satisfied: numpy in /home/evan/anaconda3/lib/python3.11/site-packages (from openai-whisper==20230918) (1.24.3)\n",
      "Collecting torch (from openai-whisper==20230918)\n",
      "  Downloading torch-2.0.1-cp311-cp311-manylinux1_x86_64.whl (619.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:07\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /home/evan/anaconda3/lib/python3.11/site-packages (from openai-whisper==20230918) (4.65.0)\n",
      "Requirement already satisfied: more-itertools in /home/evan/anaconda3/lib/python3.11/site-packages (from openai-whisper==20230918) (8.12.0)\n",
      "Collecting tiktoken==0.3.3 (from openai-whisper==20230918)\n",
      "  Downloading tiktoken-0.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /home/evan/anaconda3/lib/python3.11/site-packages (from tiktoken==0.3.3->openai-whisper==20230918) (2022.7.9)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/evan/anaconda3/lib/python3.11/site-packages (from tiktoken==0.3.3->openai-whisper==20230918) (2.31.0)\n",
      "Collecting cmake (from triton==2.0.0->openai-whisper==20230918)\n",
      "  Obtaining dependency information for cmake from https://files.pythonhosted.org/packages/de/94/cba4b3ddc0d4555967cce8fd6e9fbced98a6bf62857db71c2400a7b6e183/cmake-3.27.5-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata\n",
      "  Using cached cmake-3.27.5-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: filelock in /home/evan/anaconda3/lib/python3.11/site-packages (from triton==2.0.0->openai-whisper==20230918) (3.9.0)\n",
      "Collecting lit (from triton==2.0.0->openai-whisper==20230918)\n",
      "  Using cached lit-16.0.6.tar.gz (153 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in /home/evan/anaconda3/lib/python3.11/site-packages (from numba->openai-whisper==20230918) (0.40.0)\n",
      "Requirement already satisfied: typing-extensions in /home/evan/anaconda3/lib/python3.11/site-packages (from torch->openai-whisper==20230918) (4.7.1)\n",
      "Requirement already satisfied: sympy in /home/evan/anaconda3/lib/python3.11/site-packages (from torch->openai-whisper==20230918) (1.11.1)\n",
      "Requirement already satisfied: networkx in /home/evan/anaconda3/lib/python3.11/site-packages (from torch->openai-whisper==20230918) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/evan/anaconda3/lib/python3.11/site-packages (from torch->openai-whisper==20230918) (3.1.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch->openai-whisper==20230918)\n",
      "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m320.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch->openai-whisper==20230918)\n",
      "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m491.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101 (from torch->openai-whisper==20230918)\n",
      "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m534.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch->openai-whisper==20230918)\n",
      "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m622.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:13\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch->openai-whisper==20230918)\n",
      "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m515.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:12\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch->openai-whisper==20230918)\n",
      "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:04\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91 (from torch->openai-whisper==20230918)\n",
      "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1 (from torch->openai-whisper==20230918)\n",
      "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91 (from torch->openai-whisper==20230918)\n",
      "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3 (from torch->openai-whisper==20230918)\n",
      "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:03\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91 (from torch->openai-whisper==20230918)\n",
      "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /home/evan/anaconda3/lib/python3.11/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->openai-whisper==20230918) (68.0.0)\n",
      "Requirement already satisfied: wheel in /home/evan/anaconda3/lib/python3.11/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->openai-whisper==20230918) (0.38.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/evan/anaconda3/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper==20230918) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/evan/anaconda3/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper==20230918) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/evan/anaconda3/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper==20230918) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/evan/anaconda3/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper==20230918) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/evan/anaconda3/lib/python3.11/site-packages (from jinja2->torch->openai-whisper==20230918) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/evan/anaconda3/lib/python3.11/site-packages (from sympy->torch->openai-whisper==20230918) (1.3.0)\n",
      "Using cached cmake-3.27.5-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (26.1 MB)\n",
      "Building wheels for collected packages: openai-whisper, lit\n",
      "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for openai-whisper: filename=openai_whisper-20230918-py3-none-any.whl size=798399 sha256=9560e4618d344e644545eb52c8cc227175ab718974e687451b2295d9a7d4fbc3\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-980vg6qu/wheels/1f/1d/98/9583695e6695a6ac0ad42d87511097dce5ba486647dbfecb0e\n",
      "  Building wheel for lit (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lit: filename=lit-16.0.6-py3-none-any.whl size=93584 sha256=70c7be960938b1641d264fcfc64630358fdce365f2b6b0737ea20cc5bdaf7c17\n",
      "  Stored in directory: /home/evan/.cache/pip/wheels/ab/84/e4/5af8c76af9e5bee472e825f1451c18bb3b261d80a7b3ec7f8a\n",
      "Successfully built openai-whisper lit\n",
      "Installing collected packages: lit, cmake, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, tiktoken, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch, openai-whisper\n",
      "Successfully installed cmake-3.27.5 lit-16.0.6 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 openai-whisper-20230918 tiktoken-0.3.3 torch-2.0.1 triton-2.0.0\n",
      "Collecting jiwer\n",
      "  Obtaining dependency information for jiwer from https://files.pythonhosted.org/packages/0d/4f/ee537ab20144811dd99321735ff92ef2b3a3230b77ed7454bed4c44d21fc/jiwer-3.0.3-py3-none-any.whl.metadata\n",
      "  Downloading jiwer-3.0.3-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting click<9.0.0,>=8.1.3 (from jiwer)\n",
      "  Obtaining dependency information for click<9.0.0,>=8.1.3 from https://files.pythonhosted.org/packages/00/2e/d53fa4befbf2cfa713304affc7ca780ce4fc1fd8710527771b58311a3229/click-8.1.7-py3-none-any.whl.metadata\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting rapidfuzz<4,>=3 (from jiwer)\n",
      "  Obtaining dependency information for rapidfuzz<4,>=3 from https://files.pythonhosted.org/packages/41/bf/77fa8df72e3659a80a3ce10d2cf1751b40b6ad94652ca54b19d74f5d8f06/rapidfuzz-3.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading rapidfuzz-3.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Downloading jiwer-3.0.3-py3-none-any.whl (21 kB)\n",
      "Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m459.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading rapidfuzz-3.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m447.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: rapidfuzz, click, jiwer\n",
      "  Attempting uninstall: click\n",
      "    Found existing installation: click 8.0.4\n",
      "    Uninstalling click-8.0.4:\n",
      "      Successfully uninstalled click-8.0.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spyder 5.4.3 requires pyqt5<5.16, which is not installed.\n",
      "spyder 5.4.3 requires pyqtwebengine<5.16, which is not installed.\n",
      "python-lsp-black 1.2.1 requires black>=22.3.0, but you have black 0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed click-8.1.7 jiwer-3.0.3 rapidfuzz-3.3.0\n"
     ]
    }
   ],
   "source": [
    "! pip install git+https://github.com/openai/whisper.git\n",
    "! pip install jiwer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1IMEkgyagYto"
   },
   "source": [
    "# Loading the LibriSpeech dataset\n",
    "\n",
    "The following will load the test-clean split of the LibriSpeech corpus using torchaudio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.0.2-cp311-cp311-manylinux1_x86_64.whl (4.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hRequirement already satisfied: torch==2.0.1 in /home/evan/anaconda3/lib/python3.11/site-packages (from torchaudio) (2.0.1)\n",
      "Requirement already satisfied: filelock in /home/evan/anaconda3/lib/python3.11/site-packages (from torch==2.0.1->torchaudio) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /home/evan/anaconda3/lib/python3.11/site-packages (from torch==2.0.1->torchaudio) (4.7.1)\n",
      "Requirement already satisfied: sympy in /home/evan/anaconda3/lib/python3.11/site-packages (from torch==2.0.1->torchaudio) (1.11.1)\n",
      "Requirement already satisfied: networkx in /home/evan/anaconda3/lib/python3.11/site-packages (from torch==2.0.1->torchaudio) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/evan/anaconda3/lib/python3.11/site-packages (from torch==2.0.1->torchaudio) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/evan/anaconda3/lib/python3.11/site-packages (from torch==2.0.1->torchaudio) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/evan/anaconda3/lib/python3.11/site-packages (from torch==2.0.1->torchaudio) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/evan/anaconda3/lib/python3.11/site-packages (from torch==2.0.1->torchaudio) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/evan/anaconda3/lib/python3.11/site-packages (from torch==2.0.1->torchaudio) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/evan/anaconda3/lib/python3.11/site-packages (from torch==2.0.1->torchaudio) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/evan/anaconda3/lib/python3.11/site-packages (from torch==2.0.1->torchaudio) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/evan/anaconda3/lib/python3.11/site-packages (from torch==2.0.1->torchaudio) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/evan/anaconda3/lib/python3.11/site-packages (from torch==2.0.1->torchaudio) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/evan/anaconda3/lib/python3.11/site-packages (from torch==2.0.1->torchaudio) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/evan/anaconda3/lib/python3.11/site-packages (from torch==2.0.1->torchaudio) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/evan/anaconda3/lib/python3.11/site-packages (from torch==2.0.1->torchaudio) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/evan/anaconda3/lib/python3.11/site-packages (from torch==2.0.1->torchaudio) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /home/evan/anaconda3/lib/python3.11/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->torchaudio) (68.0.0)\n",
      "Requirement already satisfied: wheel in /home/evan/anaconda3/lib/python3.11/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->torchaudio) (0.38.4)\n",
      "Requirement already satisfied: cmake in /home/evan/anaconda3/lib/python3.11/site-packages (from triton==2.0.0->torch==2.0.1->torchaudio) (3.27.5)\n",
      "Requirement already satisfied: lit in /home/evan/anaconda3/lib/python3.11/site-packages (from triton==2.0.0->torch==2.0.1->torchaudio) (16.0.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/evan/anaconda3/lib/python3.11/site-packages (from jinja2->torch==2.0.1->torchaudio) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/evan/anaconda3/lib/python3.11/site-packages (from sympy->torch==2.0.1->torchaudio) (1.3.0)\n",
      "Installing collected packages: torchaudio\n",
      "Successfully installed torchaudio-2.0.2\n"
     ]
    }
   ],
   "source": [
    "! pip install torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "3CqtR2Fi5-vP"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mwhisper\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39maudio\u001b[39;00m \u001b[39mimport\u001b[39;00m pad_or_trim, log_mel_spectrogram\n\u001b[1;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mwhisper\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m__init__\u001b[39;00m \u001b[39mimport\u001b[39;00m load_model\n\u001b[1;32m     13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mwhisper\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdecoding\u001b[39;00m \u001b[39mimport\u001b[39;00m DecodingOptions\n",
      "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    import tensorflow  # required in Colab to avoid protobuf compatibility issues\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "from ..whisper.audio import pad_or_trim, log_mel_spectrogram\n",
    "from ..whisper.__init__ import load_model\n",
    "from ..whisper.decoding import DecodingOptions\n",
    "import torchaudio\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from pydub import AudioSegment\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "excuse me? Yeah. I don't understand why this is so complicated for people when they get here. It's just a simple form. I just need an ID. Did you get the mail? Did you send my letter? You weren't begging and he realized that the only thing that would make it better was me and says, Bride. Oh, I hadn't even thought about that.\n"
     ]
    }
   ],
   "source": [
    "sounds = [\n",
    "    AudioSegment.from_wav('/home/evan/Documents/dataset/IEMOCAP/Session1/whisper_concat_test/Ses01F_impro01_F000.wav'),\n",
    "    AudioSegment.from_wav('/home/evan/Documents/dataset/IEMOCAP/Session1/whisper_concat_test/Ses01F_impro01_F001.wav'),\n",
    "    AudioSegment.from_wav('/home/evan/Documents/dataset/IEMOCAP/Session1/whisper_concat_test/Ses01F_impro01_M011.wav'),\n",
    "    AudioSegment.from_wav('/home/evan/Documents/dataset/IEMOCAP/Session1/whisper_concat_test/Ses01F_impro02_F000.wav'),\n",
    "    AudioSegment.from_wav('/home/evan/Documents/dataset/IEMOCAP/Session1/whisper_concat_test/Ses01F_impro03_F006.wav'),\n",
    "    AudioSegment.from_wav('/home/evan/Documents/dataset/IEMOCAP/Session1/whisper_concat_test/Ses01F_impro03_F010.wav'),\n",
    "]\n",
    "\n",
    "audio = sounds[0]\n",
    "for i in range(1,len(sounds)):\n",
    "    audio = audio.append(sounds[i])\n",
    "\n",
    "audio.export(\"/home/evan/Documents/dataset/IEMOCAP/Session1/whisper_concat_test/concat.wav\", format=\"wav\")\n",
    "waveform, sample_rate = torchaudio.load(\"/home/evan/Documents/dataset/IEMOCAP/Session1/whisper_concat_test/concat.wav\")\n",
    "\n",
    "audio = pad_or_trim(waveform.flatten()).to(DEVICE)\n",
    "mel = log_mel_spectrogram(audio)\n",
    "model = load_model(\"base.en\")\n",
    "options = DecodingOptions(language=\"en\", without_timestamps=True, prompt=\"You are given 6 speech, please identify their emotions. Answer: neutral, neutral, angry, sad, happy, and\")\n",
    "result = model.decode(mel, options)\n",
    "print(result.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "GuCCB2KYOJCE"
   },
   "outputs": [],
   "source": [
    "class IEMOCAP(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    A simple class to wrap LibriSpeech and trim/pad the audio to 30 seconds.\n",
    "    It will drop the last few seconds of a very small portion of the utterances.\n",
    "    \"\"\"\n",
    "    def __init__(self, split=\"test-clean\", device=DEVICE):\n",
    "        self.dataset = torchaudio.datasets.IEMOCAP(\n",
    "            root='/home/evan/Documents/dataset/IEMOCAP',\n",
    "            sessions = (1,2,3,4,5),\n",
    "        )\n",
    "        self.device = device\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        audio, sample_rate, _, label, _ = self.dataset[item]\n",
    "        assert sample_rate == 16000\n",
    "        audio = whisper.pad_or_trim(audio.flatten()).to(self.device)\n",
    "        mel = whisper.log_mel_spectrogram(audio)\n",
    "        \n",
    "        return (mel, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "-YcRU5jqNqo2"
   },
   "outputs": [],
   "source": [
    "dataset = LibriSpeech(\"test-clean\")\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ljocCNuUAde"
   },
   "source": [
    "# Running inference on the dataset using a base Whisper model\n",
    "\n",
    "The following will take a few minutes to transcribe all utterances in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_PokfNJtOYNu",
    "outputId": "2c53ec44-bc93-4107-b4fa-214e3f71fe8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is English-only and has 71,825,408 parameters.\n"
     ]
    }
   ],
   "source": [
    "model = whisper.load_model(\"base.en\")\n",
    "print(\n",
    "    f\"Model is {'multilingual' if model.is_multilingual else 'English-only'} \"\n",
    "    f\"and has {sum(np.prod(p.shape) for p in model.parameters()):,} parameters.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict without timestamps for short-form transcription\n",
    "options = whisper.DecodingOptions(language=\"en\", without_timestamps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "09a29a91f58d4462942505a3cc415801",
      "83391f98a240490987c397048fc1a0d4",
      "06b9aa5f49fa44ba8c93b647dc7db224",
      "da9c231ee67047fb89073c95326b72a5",
      "48da931ebe7f4fd299f8c98c7d2460ff",
      "7a901f447c1d477bb49f954e0feacedd",
      "39f5a6ae8ba74c8598f9c6d5b8ad2d65",
      "a0d10a42c753453283e5219c22239337",
      "09f4cb79ff86465aaf48b0de24869af9",
      "1b9cecf5b3584fba8258a81d4279a25b",
      "039b53f2702c4179af7e0548018d0588"
     ]
    },
    "id": "7OWTn_KvNk59",
    "outputId": "a813a792-3c91-4144-f11f-054fd6778023"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45339251c3774bf88a0a91b444a55cd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/164 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DecodingResult(audio_features=tensor([[-1.0576,  0.3557, -1.0889,  ...,  0.4553, -0.7871,  0.0673],\n",
      "        [-0.2568,  0.0029, -0.1195,  ...,  0.1710, -0.3689,  0.3582],\n",
      "        [-0.2654,  0.0019,  0.0253,  ...,  0.1702,  0.0403, -0.0301],\n",
      "        ...,\n",
      "        [ 0.2607, -0.3406, -0.7217,  ...,  0.8687,  0.0341,  0.5186],\n",
      "        [ 0.4514, -0.1913, -0.5493,  ...,  0.8955, -0.1149,  0.2500],\n",
      "        [ 0.5615, -0.6660,  0.3049,  ...,  0.6152, -0.3379,  0.1537]],\n",
      "       device='cuda:0', dtype=torch.float16), language='en', language_probs=None, tokens=[679, 10719, 612, 561, 307, 20798, 329, 8073, 11, 1210, 2419, 290, 34397, 290, 44379, 18821, 290, 3735, 4517, 1122, 5207, 284, 307, 9717, 992, 503, 287, 6546, 11, 49038, 1068, 15061, 12, 17359, 268, 10746, 13], text='He hoped there would be stew for dinner, turnips and carrots and bruised potatoes and fat mutton pieces to be ladled out in thick, peppered flower-faten sauce.', avg_logprob=-0.17884910734076248, no_speech_prob=0.04064858332276344, temperature=0.0, compression_ratio=1.347457627118644), DecodingResult(audio_features=tensor([[-1.0791,  0.1236, -1.4082,  ...,  0.4944,  0.3555, -0.6221],\n",
      "        [-0.2322, -0.3386, -0.2440,  ...,  0.5234,  0.1729, -0.3342],\n",
      "        [-0.4597, -0.1724, -0.1346,  ...,  0.5029,  0.3743, -0.2032],\n",
      "        ...,\n",
      "        [ 0.5176, -0.3013, -0.5015,  ...,  0.8496, -0.2825,  0.4482],\n",
      "        [ 0.9639, -0.2253, -0.0134,  ...,  0.8491, -0.5112, -0.0559],\n",
      "        [ 0.9053, -0.6533,  0.5342,  ...,  0.5474, -0.6099, -0.1680]],\n",
      "       device='cuda:0', dtype=torch.float16), language='en', language_probs=None, tokens=[520, 1648, 1068, 656, 345, 11, 465, 19921, 7739, 276, 683, 13], text='Stuffered into you, his belly counseled him.', avg_logprob=-0.2644915030552791, no_speech_prob=0.02159211039543152, temperature=0.0, compression_ratio=0.8627450980392157), DecodingResult(audio_features=tensor([[-1.3721,  0.0234, -1.0352,  ...,  0.4053, -0.2642, -0.2225],\n",
      "        [-1.0137, -0.4102,  0.1893,  ...,  0.4438,  0.2681,  1.0713],\n",
      "        [-0.7900, -0.4988,  0.6929,  ..., -0.0419,  1.2480,  0.5557],\n",
      "        ...,\n",
      "        [ 0.3701, -0.4976, -0.7861,  ...,  0.8970, -0.2507,  0.4619],\n",
      "        [ 0.7808, -0.3062, -0.2754,  ...,  0.9883, -0.3953,  0.1287],\n",
      "        [ 0.7568, -0.6772,  0.4832,  ...,  0.5933, -0.5249,  0.0750]],\n",
      "       device='cuda:0', dtype=torch.float16), language='en', language_probs=None, tokens=[2293, 1903, 1755, 7207, 262, 7872, 32209, 561, 1657, 510, 994, 290, 612, 262, 2809, 10751, 3860, 286, 262, 1379, 1169, 7278, 13], text='After early nightfall the yellow lamps would light up here and there the squalid quarter of the brothels.', avg_logprob=-0.07326684892177582, no_speech_prob=0.020819352939724922, temperature=0.0, compression_ratio=1.206896551724138), DecodingResult(audio_features=tensor([[-1.2871,  0.6035, -0.6851,  ...,  0.6113, -0.5205,  0.3120],\n",
      "        [-0.4309, -0.0213,  0.1389,  ...,  0.4675, -0.1193,  0.5928],\n",
      "        [-0.0803, -0.1638,  0.1074,  ...,  0.2568,  0.5454,  0.3967],\n",
      "        ...,\n",
      "        [ 0.2668, -0.2776, -0.5400,  ...,  0.9272, -0.2622,  0.6670],\n",
      "        [ 0.6689, -0.1242, -0.1466,  ...,  0.9668, -0.5049,  0.1281],\n",
      "        [ 0.7114, -0.5918,  0.3562,  ...,  0.5781, -0.5498, -0.0767]],\n",
      "       device='cuda:0', dtype=torch.float16), language='en', language_probs=None, tokens=[18435, 22108, 494, 11, 597, 922, 287, 534, 2000, 30], text='Hello Bertie, any good in your mind?', avg_logprob=-0.11186562884937633, no_speech_prob=0.022614771500229836, temperature=0.0, compression_ratio=0.8181818181818182), DecodingResult(audio_features=tensor([[-1.1836,  0.4275, -0.3328,  ...,  0.6162, -0.1070,  0.4902],\n",
      "        [-0.2969, -0.2106,  0.6782,  ...,  0.6079,  0.1884,  1.2412],\n",
      "        [-0.4858,  0.0659,  0.6924,  ...,  0.4316,  0.2365,  0.9844],\n",
      "        ...,\n",
      "        [ 0.4302, -0.4573, -0.7715,  ...,  0.9131, -0.2290,  0.6802],\n",
      "        [ 0.7583, -0.2412, -0.3191,  ...,  0.9165, -0.3296,  0.2311],\n",
      "        [ 0.7598, -0.6201,  0.3530,  ...,  0.5479, -0.4773,  0.0406]],\n",
      "       device='cuda:0', dtype=torch.float16), language='en', language_probs=None, tokens=[7913, 838, 13, 20138, 399, 6148, 318, 4953, 319, 345, 13, 4599, 1755, 11, 5229, 13], text='Number 10. Fresh Nelly is waiting on you. Good night, husband.', avg_logprob=-0.2720224997576545, no_speech_prob=0.056919168680906296, temperature=0.0, compression_ratio=0.8857142857142857), DecodingResult(audio_features=tensor([[-1.0449,  0.1453, -1.0645,  ...,  0.6777,  0.0134, -0.4092],\n",
      "        [ 0.1273, -0.0508, -0.0260,  ...,  0.2815,  0.3713,  0.1217],\n",
      "        [-0.0717,  0.0081,  0.3132,  ..., -0.0046,  0.9644,  0.1320],\n",
      "        ...,\n",
      "        [ 0.4426, -0.4966, -0.6504,  ...,  0.9253, -0.2209,  0.4434],\n",
      "        [ 0.6572, -0.3308, -0.3684,  ...,  0.9697, -0.2177,  0.1411],\n",
      "        [ 0.6885, -0.6875,  0.3750,  ...,  0.6235, -0.4136,  0.1412]],\n",
      "       device='cuda:0', dtype=torch.float16), language='en', language_probs=None, tokens=[383, 2647, 1625, 40671, 11, 290, 339, 12433, 262, 2456, 11, 262, 2456, 286, 46854, 338, 24225, 2402, 262, 8824, 24504, 15185, 1203, 11, 14005, 329, 5806, 1272, 13], text=\"The music came nearer, and he recalled the words, the words of Shelley's fragment upon the moon wandering companionless, pale for weariness.\", avg_logprob=-0.11968368689219157, no_speech_prob=0.04736045375466347, temperature=0.0, compression_ratio=1.2727272727272727), DecodingResult(audio_features=tensor([[-1.1953,  0.1594, -0.5454,  ...,  0.4229, -0.5610, -0.1733],\n",
      "        [-0.4250, -0.1045, -0.0273,  ...,  0.2878, -0.3311,  0.2903],\n",
      "        [-0.4238, -0.1512,  0.3325,  ...,  0.0265,  0.3765, -0.0811],\n",
      "        ...,\n",
      "        [ 0.3540, -0.2905, -0.7051,  ...,  0.8989,  0.0135,  0.5537],\n",
      "        [ 0.5586, -0.2134, -0.5127,  ...,  0.8750, -0.1410,  0.2407],\n",
      "        [ 0.6743, -0.7144,  0.3560,  ...,  0.5991, -0.3533,  0.1553]],\n",
      "       device='cuda:0', dtype=torch.float16), language='en', language_probs=None, tokens=[383, 19222, 1657, 3214, 517, 49057, 2402, 262, 2443, 11, 810, 319, 1194, 16022, 2540, 284, 16631, 2346, 6364, 11, 290, 284, 4104, 10522, 663, 38118, 7894, 13], text='The dull light fell more faintly upon the page, where on another equation began to unfold itself slowly, and to spread abroad its widening tail.', avg_logprob=-0.06360198300460289, no_speech_prob=0.005151625722646713, temperature=0.0, compression_ratio=1.2857142857142858), DecodingResult(audio_features=tensor([[-0.7847,  0.0127, -1.1602,  ...,  0.2588, -0.5835,  0.1376],\n",
      "        [-0.1260, -0.5815, -0.3850,  ...,  0.3604,  0.0030,  0.4482],\n",
      "        [-0.2744, -0.8813, -0.0665,  ...,  0.4187,  0.8472,  0.0450],\n",
      "        ...,\n",
      "        [ 0.2783, -0.4626, -0.6870,  ...,  0.9102, -0.1749,  0.5835],\n",
      "        [ 0.7651, -0.2490, -0.1957,  ...,  0.9688, -0.4465,  0.1616],\n",
      "        [ 0.7598, -0.6699,  0.3757,  ...,  0.6089, -0.5786, -0.0199]],\n",
      "       device='cuda:0', dtype=torch.float16), language='en', language_probs=None, tokens=[317, 4692, 11, 45464, 34324, 302, 3916, 287, 465, 5848, 13], text='A cold, lucid indifference reigned in his soul.', avg_logprob=-0.1220417320728302, no_speech_prob=0.028905216604471207, temperature=0.0, compression_ratio=0.8867924528301887), DecodingResult(audio_features=tensor([[-1.0332,  0.3616, -1.0195,  ...,  0.4236, -0.2891,  0.2046],\n",
      "        [-0.2546, -0.1755, -0.1591,  ...,  0.4414, -0.1960,  0.4470],\n",
      "        [-0.2671,  0.2610, -0.3955,  ...,  0.2030,  0.4094,  0.0965],\n",
      "        ...,\n",
      "        [ 0.2617, -0.5068, -0.8535,  ...,  0.9546, -0.2842,  0.6313],\n",
      "        [ 0.6802, -0.2798, -0.3994,  ...,  1.0186, -0.4956,  0.2649],\n",
      "        [ 0.6831, -0.6851,  0.2986,  ...,  0.6055, -0.4827,  0.1620]],\n",
      "       device='cuda:0', dtype=torch.float16), language='en', language_probs=None, tokens=[383, 11918, 287, 543, 465, 1502, 42774, 2346, 373, 257, 4692, 11, 31655, 3725, 286, 2241, 13], text='The chaos in which his order extinguished itself was a cold, indifferent knowledge of himself.', avg_logprob=-0.11761393811967638, no_speech_prob=0.023763436824083328, temperature=0.0, compression_ratio=1.119047619047619), DecodingResult(audio_features=tensor([[-1.1602,  0.1277, -1.1562,  ...,  0.6108, -0.1906,  0.0042],\n",
      "        [-0.7153, -0.1970, -0.1722,  ...,  0.2717, -0.0976,  0.7861],\n",
      "        [-0.6323, -0.2277,  0.2362,  ..., -0.0645,  0.8003,  0.4343],\n",
      "        ...,\n",
      "        [ 0.6548, -0.2754, -0.3792,  ...,  0.7227, -0.1536,  0.4121],\n",
      "        [ 0.8843, -0.2236, -0.1427,  ...,  0.7256, -0.1833,  0.1521],\n",
      "        [ 0.7554, -0.6875,  0.5405,  ...,  0.5815, -0.4255,  0.0671]],\n",
      "       device='cuda:0', dtype=torch.float16), language='en', language_probs=None, tokens=[1629, 749, 11, 416, 281, 435, 907, 1813, 284, 257, 44887, 283, 3025, 20027, 339, 11468, 422, 11, 339, 1244, 2911, 356, 3093, 284, 1592, 329, 2241, 617, 3953, 286, 4036, 11542, 13], text='At most, by an alms given to a beggar whose blessing he fled from, he might hope wearily to win for himself some measure of actual grace.', avg_logprob=-0.0446234801236321, no_speech_prob=0.009677066467702389, temperature=0.0, compression_ratio=1.2568807339449541), DecodingResult(audio_features=tensor([[-1.2266,  0.5508, -1.0430,  ...,  0.4380, -0.5703, -0.0364],\n",
      "        [-0.3489, -0.1390, -0.1271,  ...,  0.0516, -0.0579,  0.3640],\n",
      "        [-0.7100,  0.0790, -0.0978,  ...,  0.0400,  0.1786, -0.0022],\n",
      "        ...,\n",
      "        [ 0.3887, -0.3342, -0.4497,  ...,  0.8105, -0.3591,  0.6118],\n",
      "        [ 0.8408, -0.1685,  0.0540,  ...,  0.8228, -0.5010,  0.0660],\n",
      "        [ 0.7817, -0.6475,  0.5176,  ...,  0.5259, -0.6621, -0.1119]],\n",
      "       device='cuda:0', dtype=torch.float16), language='en', language_probs=None, tokens=[3894, 783, 2039, 21361, 11, 314, 13627, 345, 423, 257, 1182, 290, 523, 468, 616, 4859, 13], text='Well now Ennis, I declare you have a head and so has my stick.', avg_logprob=-0.16724618275960287, no_speech_prob=0.0953742116689682, temperature=0.0, compression_ratio=0.8985507246376812), DecodingResult(audio_features=tensor([[-0.9941,  0.2715, -0.6792,  ...,  0.1582, -0.9004,  0.1605],\n",
      "        [-0.9497,  0.2683, -0.1140,  ..., -0.1305, -0.1141,  0.8618],\n",
      "        [-0.6284, -0.1375,  0.1582,  ..., -0.0691, -0.2448,  0.4641],\n",
      "        ...,\n",
      "        [ 0.5806, -0.4614, -0.6338,  ...,  0.7490, -0.1552,  0.3208],\n",
      "        [ 0.7168, -0.2786, -0.4260,  ...,  0.8496, -0.1832,  0.1458],\n",
      "        [ 0.6953, -0.6968,  0.4487,  ...,  0.5815, -0.3838,  0.1320]],\n",
      "       device='cuda:0', dtype=torch.float16), language='en', language_probs=None, tokens=[1550, 3909, 31143, 11, 618, 262, 523, 12, 67, 1483, 1138, 287, 262, 43398, 284, 46528, 262, 1310, 2607, 11, 465, 1295, 373, 257, 24736, 14994, 42687, 6915, 379, 262, 826, 286, 262, 18890, 422, 543, 339, 2957, 465, 8539, 286, 6510, 832, 262, 9109, 13], text='On Saturday mornings, when the so-dality met in the chapel to recite the little office, his place was a cushioned kneeling desk at the right of the altar from which he led his wing of boys through the responses.', avg_logprob=-0.1200893077444523, no_speech_prob=0.03226066008210182, temperature=0.0, compression_ratio=1.4452054794520548), DecodingResult(audio_features=tensor([[-1.0771, -0.0173, -0.6440,  ...,  0.4382, -0.5347,  0.1570],\n",
      "        [-0.2042, -0.7300,  0.2668,  ...,  0.0284, -0.1575,  0.5225],\n",
      "        [-0.0106, -0.2786,  0.4993,  ..., -0.0934,  0.1249,  0.3574],\n",
      "        ...,\n",
      "        [ 0.4351, -0.5024, -0.8267,  ...,  0.8604,  0.0127,  0.4802],\n",
      "        [ 0.5898, -0.3628, -0.5474,  ...,  0.9893, -0.1265,  0.3521],\n",
      "        [ 0.6553, -0.7388,  0.3428,  ...,  0.6724, -0.3330,  0.2090]],\n",
      "       device='cuda:0', dtype=torch.float16), language='en', language_probs=None, tokens=[2332, 2951, 3947, 284, 2754, 683, 351, 11607, 26246, 13, 2332, 6039, 1272, 11, 257, 6283, 1657, 21377, 49057, 2402, 607, 41890, 11222, 11, 750, 407, 22251, 378, 262, 264, 5083, 508, 10448, 607, 13], text='Her eyes seemed to regard him with mild pity. Her holiness, a strange light glowing faintly upon her frail flesh, did not humiliate the sinner who approached her.', avg_logprob=-0.018930547767215304, no_speech_prob=0.012483366765081882, temperature=0.0, compression_ratio=1.3388429752066116), DecodingResult(audio_features=tensor([[-1.2080,  0.0331, -1.0176,  ...,  0.2852,  0.2859,  0.0372],\n",
      "        [-0.3811, -0.3896,  0.0734,  ...,  0.3171,  0.3232,  0.4197],\n",
      "        [-0.2233, -0.6123,  0.2703,  ...,  0.0024,  0.8071,  0.2244],\n",
      "        ...,\n",
      "        [ 0.5205, -0.4644, -0.6519,  ...,  0.9155, -0.3394,  0.4456],\n",
      "        [ 0.8633, -0.2871, -0.2408,  ...,  0.9595, -0.4128,  0.0801],\n",
      "        [ 0.7896, -0.6772,  0.4102,  ...,  0.6382, -0.5620,  0.0997]],\n",
      "       device='cuda:0', dtype=torch.float16), language='en', language_probs=None, tokens=[1002, 1683, 339, 373, 545, 15803, 284, 3350, 7813, 422, 683, 290, 284, 28787, 11, 262, 25278, 326, 3888, 683, 373, 262, 4601, 284, 307, 607, 1755, 13], text='If ever he was impelled to cast sin from him and to repent, the impulse that moved him was the wish to be her night.', avg_logprob=-0.05383413002408784, no_speech_prob=0.014162132516503334, temperature=0.0, compression_ratio=1.2340425531914894), DecodingResult(audio_features=tensor([[-1.1191,  0.4529, -1.0283,  ...,  0.5562, -0.5015, -0.3936],\n",
      "        [-0.7881, -0.0753,  0.1821,  ...,  0.5278, -0.2959,  0.0893],\n",
      "        [-0.7729, -0.3582,  0.4648,  ...,  0.0341,  0.8828, -0.0020],\n",
      "        ...,\n",
      "        [ 0.6011, -0.3044, -0.5103,  ...,  0.9082, -0.5479,  0.4937],\n",
      "        [ 1.0264, -0.0893,  0.0325,  ...,  0.8511, -0.7021, -0.0912],\n",
      "        [ 0.9404, -0.5894,  0.5190,  ...,  0.5107, -0.7144, -0.1718]],\n",
      "       device='cuda:0', dtype=torch.float16), language='en', language_probs=None, tokens=[679, 3088, 284, 892, 703, 340, 714, 307, 13], text='He tried to think how it could be.', avg_logprob=-0.06675245761871337, no_speech_prob=0.026221321895718575, temperature=0.0, compression_ratio=0.8095238095238095), DecodingResult(audio_features=tensor([[-0.8140,  0.3430, -1.6113,  ...,  1.0859,  0.1542, -0.1307],\n",
      "        [-0.1672,  0.2329, -1.3164,  ...,  1.2842, -0.5420,  0.8643],\n",
      "        [ 0.1379, -0.1606, -1.2949,  ...,  1.2402, -1.0938,  0.9604],\n",
      "        ...,\n",
      "        [ 0.3396, -0.4597, -0.7925,  ...,  0.9404, -0.2222,  0.6162],\n",
      "        [ 0.7837, -0.2891, -0.3867,  ...,  1.0254, -0.4932,  0.1903],\n",
      "        [ 0.8320, -0.6743,  0.3147,  ...,  0.6362, -0.5684,  0.0790]],\n",
      "       device='cuda:0', dtype=torch.float16), language='en', language_probs=None, tokens=[475, 262, 46166, 46539, 287, 262, 1524, 3823, 5017, 625, 465, 6066, 13, 383, 8966, 28077, 13], text='but the dusk deepening in the schoolroom covered over his thoughts. The bell rang.', avg_logprob=-0.11810843149820964, no_speech_prob=0.013263512402772903, temperature=0.0, compression_ratio=1.0789473684210527)]\n"
     ]
    }
   ],
   "source": [
    "hypotheses = []\n",
    "references = []\n",
    "\n",
    "for mels, texts in tqdm(loader):\n",
    "    results = model.decode(mels, options)\n",
    "    print(results)\n",
    "    hypotheses.extend([result.text for result in results])\n",
    "    references.extend(texts)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "4nTyynELQ42j",
    "outputId": "1c72d25a-3e87-4c60-a8d1-1da9d2f73bd7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>reference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>He hoped there would be stew for dinner, turni...</td>\n",
       "      <td>HE HOPED THERE WOULD BE STEW FOR DINNER TURNIP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stuffered into you, his belly counseled him.</td>\n",
       "      <td>STUFF IT INTO YOU HIS BELLY COUNSELLED HIM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>After early nightfall the yellow lamps would l...</td>\n",
       "      <td>AFTER EARLY NIGHTFALL THE YELLOW LAMPS WOULD L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hello Bertie, any good in your mind?</td>\n",
       "      <td>HELLO BERTIE ANY GOOD IN YOUR MIND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Number 10. Fresh Nelly is waiting on you. Good...</td>\n",
       "      <td>NUMBER TEN FRESH NELLY IS WAITING ON YOU GOOD ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The music came nearer, and he recalled the wor...</td>\n",
       "      <td>THE MUSIC CAME NEARER AND HE RECALLED THE WORD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The dull light fell more faintly upon the page...</td>\n",
       "      <td>THE DULL LIGHT FELL MORE FAINTLY UPON THE PAGE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A cold, lucid indifference reigned in his soul.</td>\n",
       "      <td>A COLD LUCID INDIFFERENCE REIGNED IN HIS SOUL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The chaos in which his order extinguished itse...</td>\n",
       "      <td>THE CHAOS IN WHICH HIS ARDOUR EXTINGUISHED ITS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>At most, by an alms given to a beggar whose bl...</td>\n",
       "      <td>AT MOST BY AN ALMS GIVEN TO A BEGGAR WHOSE BLE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Well now Ennis, I declare you have a head and ...</td>\n",
       "      <td>WELL NOW ENNIS I DECLARE YOU HAVE A HEAD AND S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>On Saturday mornings, when the so-dality met i...</td>\n",
       "      <td>ON SATURDAY MORNINGS WHEN THE SODALITY MET IN ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Her eyes seemed to regard him with mild pity. ...</td>\n",
       "      <td>HER EYES SEEMED TO REGARD HIM WITH MILD PITY H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>If ever he was impelled to cast sin from him a...</td>\n",
       "      <td>IF EVER HE WAS IMPELLED TO CAST SIN FROM HIM A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>He tried to think how it could be.</td>\n",
       "      <td>HE TRIED TO THINK HOW IT COULD BE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>but the dusk deepening in the schoolroom cover...</td>\n",
       "      <td>BUT THE DUSK DEEPENING IN THE SCHOOLROOM COVER...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           hypothesis  \\\n",
       "0   He hoped there would be stew for dinner, turni...   \n",
       "1        Stuffered into you, his belly counseled him.   \n",
       "2   After early nightfall the yellow lamps would l...   \n",
       "3                Hello Bertie, any good in your mind?   \n",
       "4   Number 10. Fresh Nelly is waiting on you. Good...   \n",
       "5   The music came nearer, and he recalled the wor...   \n",
       "6   The dull light fell more faintly upon the page...   \n",
       "7     A cold, lucid indifference reigned in his soul.   \n",
       "8   The chaos in which his order extinguished itse...   \n",
       "9   At most, by an alms given to a beggar whose bl...   \n",
       "10  Well now Ennis, I declare you have a head and ...   \n",
       "11  On Saturday mornings, when the so-dality met i...   \n",
       "12  Her eyes seemed to regard him with mild pity. ...   \n",
       "13  If ever he was impelled to cast sin from him a...   \n",
       "14                 He tried to think how it could be.   \n",
       "15  but the dusk deepening in the schoolroom cover...   \n",
       "\n",
       "                                            reference  \n",
       "0   HE HOPED THERE WOULD BE STEW FOR DINNER TURNIP...  \n",
       "1          STUFF IT INTO YOU HIS BELLY COUNSELLED HIM  \n",
       "2   AFTER EARLY NIGHTFALL THE YELLOW LAMPS WOULD L...  \n",
       "3                  HELLO BERTIE ANY GOOD IN YOUR MIND  \n",
       "4   NUMBER TEN FRESH NELLY IS WAITING ON YOU GOOD ...  \n",
       "5   THE MUSIC CAME NEARER AND HE RECALLED THE WORD...  \n",
       "6   THE DULL LIGHT FELL MORE FAINTLY UPON THE PAGE...  \n",
       "7       A COLD LUCID INDIFFERENCE REIGNED IN HIS SOUL  \n",
       "8   THE CHAOS IN WHICH HIS ARDOUR EXTINGUISHED ITS...  \n",
       "9   AT MOST BY AN ALMS GIVEN TO A BEGGAR WHOSE BLE...  \n",
       "10  WELL NOW ENNIS I DECLARE YOU HAVE A HEAD AND S...  \n",
       "11  ON SATURDAY MORNINGS WHEN THE SODALITY MET IN ...  \n",
       "12  HER EYES SEEMED TO REGARD HIM WITH MILD PITY H...  \n",
       "13  IF EVER HE WAS IMPELLED TO CAST SIN FROM HIM A...  \n",
       "14                  HE TRIED TO THINK HOW IT COULD BE  \n",
       "15  BUT THE DUSK DEEPENING IN THE SCHOOLROOM COVER...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(dict(hypothesis=hypotheses, reference=references))\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HPppEJRXX4ox"
   },
   "source": [
    "# Calculating the word error rate\n",
    "\n",
    "Now, we use our English normalizer implementation to standardize the transcription and calculate the WER."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "dl-KBDflMhrg"
   },
   "outputs": [],
   "source": [
    "import jiwer\n",
    "from whisper.normalizers import EnglishTextNormalizer\n",
    "\n",
    "normalizer = EnglishTextNormalizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 641
    },
    "id": "6-O048q4WI4o",
    "outputId": "f2089bc9-f535-441e-f192-26e52ae82b5e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>reference</th>\n",
       "      <th>hypothesis_clean</th>\n",
       "      <th>reference_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>He hoped there would be stew for dinner, turni...</td>\n",
       "      <td>HE HOPED THERE WOULD BE STEW FOR DINNER TURNIP...</td>\n",
       "      <td>he hoped there would be stew for dinner turnip...</td>\n",
       "      <td>he hoped there would be stew for dinner turnip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stuffered into you, his belly counseled him.</td>\n",
       "      <td>STUFF IT INTO YOU HIS BELLY COUNSELLED HIM</td>\n",
       "      <td>stuffered into you his belly counseled him</td>\n",
       "      <td>stuff it into you his belly counseled him</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>After early nightfall the yellow lamps would l...</td>\n",
       "      <td>AFTER EARLY NIGHTFALL THE YELLOW LAMPS WOULD L...</td>\n",
       "      <td>after early nightfall the yellow lamps would l...</td>\n",
       "      <td>after early nightfall the yellow lamps would l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hello Bertie, any good in your mind?</td>\n",
       "      <td>HELLO BERTIE ANY GOOD IN YOUR MIND</td>\n",
       "      <td>hello bertie any good in your mind</td>\n",
       "      <td>hello bertie any good in your mind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Number 10. Fresh Nelly is waiting on you. Good...</td>\n",
       "      <td>NUMBER TEN FRESH NELLY IS WAITING ON YOU GOOD ...</td>\n",
       "      <td>number 10 fresh nelly is waiting on you good n...</td>\n",
       "      <td>number 10 fresh nelly is waiting on you good n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2615</th>\n",
       "      <td>Oh, to shoot my soul's full meaning into futur...</td>\n",
       "      <td>OH TO SHOOT MY SOUL'S FULL MEANING INTO FUTURE...</td>\n",
       "      <td>0 to shoot my soul is full meaning into future...</td>\n",
       "      <td>0 to shoot my soul is full meaning into future...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2616</th>\n",
       "      <td>Then I, long tried by natural ills, received t...</td>\n",
       "      <td>THEN I LONG TRIED BY NATURAL ILLS RECEIVED THE...</td>\n",
       "      <td>then i long tried by natural ills received the...</td>\n",
       "      <td>then i long tried by natural ills received the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2617</th>\n",
       "      <td>I love thee freely as men strive for right. I ...</td>\n",
       "      <td>I LOVE THEE FREELY AS MEN STRIVE FOR RIGHT I L...</td>\n",
       "      <td>i love thee freely as men strive for right i l...</td>\n",
       "      <td>i love thee freely as men strive for right i l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2618</th>\n",
       "      <td>I love thee with the passion put to use, in my...</td>\n",
       "      <td>I LOVE THEE WITH THE PASSION PUT TO USE IN MY ...</td>\n",
       "      <td>i love thee with the passion put to use in my ...</td>\n",
       "      <td>i love thee with the passion put to use in my ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2619</th>\n",
       "      <td>I love thee with the love I seemed to lose wit...</td>\n",
       "      <td>I LOVE THEE WITH A LOVE I SEEMED TO LOSE WITH ...</td>\n",
       "      <td>i love thee with the love i seemed to lose wit...</td>\n",
       "      <td>i love thee with a love i seemed to lose with ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2620 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             hypothesis  \\\n",
       "0     He hoped there would be stew for dinner, turni...   \n",
       "1          Stuffered into you, his belly counseled him.   \n",
       "2     After early nightfall the yellow lamps would l...   \n",
       "3                  Hello Bertie, any good in your mind?   \n",
       "4     Number 10. Fresh Nelly is waiting on you. Good...   \n",
       "...                                                 ...   \n",
       "2615  Oh, to shoot my soul's full meaning into futur...   \n",
       "2616  Then I, long tried by natural ills, received t...   \n",
       "2617  I love thee freely as men strive for right. I ...   \n",
       "2618  I love thee with the passion put to use, in my...   \n",
       "2619  I love thee with the love I seemed to lose wit...   \n",
       "\n",
       "                                              reference  \\\n",
       "0     HE HOPED THERE WOULD BE STEW FOR DINNER TURNIP...   \n",
       "1            STUFF IT INTO YOU HIS BELLY COUNSELLED HIM   \n",
       "2     AFTER EARLY NIGHTFALL THE YELLOW LAMPS WOULD L...   \n",
       "3                    HELLO BERTIE ANY GOOD IN YOUR MIND   \n",
       "4     NUMBER TEN FRESH NELLY IS WAITING ON YOU GOOD ...   \n",
       "...                                                 ...   \n",
       "2615  OH TO SHOOT MY SOUL'S FULL MEANING INTO FUTURE...   \n",
       "2616  THEN I LONG TRIED BY NATURAL ILLS RECEIVED THE...   \n",
       "2617  I LOVE THEE FREELY AS MEN STRIVE FOR RIGHT I L...   \n",
       "2618  I LOVE THEE WITH THE PASSION PUT TO USE IN MY ...   \n",
       "2619  I LOVE THEE WITH A LOVE I SEEMED TO LOSE WITH ...   \n",
       "\n",
       "                                       hypothesis_clean  \\\n",
       "0     he hoped there would be stew for dinner turnip...   \n",
       "1            stuffered into you his belly counseled him   \n",
       "2     after early nightfall the yellow lamps would l...   \n",
       "3                    hello bertie any good in your mind   \n",
       "4     number 10 fresh nelly is waiting on you good n...   \n",
       "...                                                 ...   \n",
       "2615  0 to shoot my soul is full meaning into future...   \n",
       "2616  then i long tried by natural ills received the...   \n",
       "2617  i love thee freely as men strive for right i l...   \n",
       "2618  i love thee with the passion put to use in my ...   \n",
       "2619  i love thee with the love i seemed to lose wit...   \n",
       "\n",
       "                                        reference_clean  \n",
       "0     he hoped there would be stew for dinner turnip...  \n",
       "1             stuff it into you his belly counseled him  \n",
       "2     after early nightfall the yellow lamps would l...  \n",
       "3                    hello bertie any good in your mind  \n",
       "4     number 10 fresh nelly is waiting on you good n...  \n",
       "...                                                 ...  \n",
       "2615  0 to shoot my soul is full meaning into future...  \n",
       "2616  then i long tried by natural ills received the...  \n",
       "2617  i love thee freely as men strive for right i l...  \n",
       "2618  i love thee with the passion put to use in my ...  \n",
       "2619  i love thee with a love i seemed to lose with ...  \n",
       "\n",
       "[2620 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"hypothesis_clean\"] = [normalizer(text) for text in data[\"hypothesis\"]]\n",
    "data[\"reference_clean\"] = [normalizer(text) for text in data[\"reference\"]]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EBGSITeBYPTT",
    "outputId": "7b3dbe7c-a37e-4a07-a50a-b27d5f88b68f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER: 4.26 %\n"
     ]
    }
   ],
   "source": [
    "wer = jiwer.wer(list(data[\"reference_clean\"]), list(data[\"hypothesis_clean\"]))\n",
    "\n",
    "print(f\"WER: {wer * 100:.2f} %\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "039b53f2702c4179af7e0548018d0588": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "06b9aa5f49fa44ba8c93b647dc7db224": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a0d10a42c753453283e5219c22239337",
      "max": 164,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_09f4cb79ff86465aaf48b0de24869af9",
      "value": 164
     }
    },
    "09a29a91f58d4462942505a3cc415801": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_83391f98a240490987c397048fc1a0d4",
       "IPY_MODEL_06b9aa5f49fa44ba8c93b647dc7db224",
       "IPY_MODEL_da9c231ee67047fb89073c95326b72a5"
      ],
      "layout": "IPY_MODEL_48da931ebe7f4fd299f8c98c7d2460ff"
     }
    },
    "09f4cb79ff86465aaf48b0de24869af9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1b9cecf5b3584fba8258a81d4279a25b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "39f5a6ae8ba74c8598f9c6d5b8ad2d65": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "48da931ebe7f4fd299f8c98c7d2460ff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7a901f447c1d477bb49f954e0feacedd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "83391f98a240490987c397048fc1a0d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7a901f447c1d477bb49f954e0feacedd",
      "placeholder": "​",
      "style": "IPY_MODEL_39f5a6ae8ba74c8598f9c6d5b8ad2d65",
      "value": "100%"
     }
    },
    "a0d10a42c753453283e5219c22239337": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "da9c231ee67047fb89073c95326b72a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1b9cecf5b3584fba8258a81d4279a25b",
      "placeholder": "​",
      "style": "IPY_MODEL_039b53f2702c4179af7e0548018d0588",
      "value": " 164/164 [05:08&lt;00:00,  1.86s/it]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
